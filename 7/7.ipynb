{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python382jvsc74a57bd088d9d682369c4c2b7f978cc3aeb5771370d6cf449cc3896384a8f211d6901526",
   "display_name": "Python 3.8.2 32-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Fórmula general del aprendizaje por diferencias temporales, TDL por sus siglas en inglés. El $\\alpha$ es un amortiguador entre $0$ y $1$.\n",
    "\n",
    "$$V(s) = V(s) + \\alpha[V(s') - V(s)]$$\n",
    "\n",
    "La idea es hacer una función que, a partir de esa ecuación, simule este algoritmo:\n",
    "\n",
    "```\n",
    "ambiente\n",
    "agente\n",
    "for episodio = 0, ..., max_episodio:\n",
    "    estado = ambiente.reset()\n",
    "    agente.reset()\n",
    "    for t = 0, ..., T:\n",
    "        accion = agente.accion(estado)\n",
    "        estado, recompensa = ambiente.paso(accion)\n",
    "        agente.actualizar(acction, estado, recompensa)\n",
    "        si ambiente.fin():\n",
    "            salir\n",
    "```\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, action = 0, state = 0, reward = 0, alpha = 0.25):\n",
    "        self.action = action\n",
    "        self.state = state\n",
    "        self.reward = reward\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def action(self, state, board, i):\n",
    "        # state recibe estado del juego actual, o sea una instancia de Env\n",
    "        # board es el tablero temporal con las posibles jugadas\n",
    "        # i sirve para determinar cuántos valores se toman en adelante\n",
    "        # Se calcula la función de valor de cada acción que se pueda realizar\n",
    "        \n",
    "        # TODO: Obtener opciones disponibles marcadas con '' por posición en ps\n",
    "        ps = []\n",
    "        for p in t_board:\n",
    "            if p == '':\n",
    "                ps.append(p)\n",
    "        # Lista de funciones de valor\n",
    "        vs = []\n",
    "        for p in ps:\n",
    "            # TODO: Calcular la función de valor actual en v; de momento 1/(total de posibles jugadas)\n",
    "            # TODO: Lo ideal sería comprobar si ya ganó. Se puede crear una matriz de posibles victorias.\n",
    "            t_board = board[p] = str(state.turn % 2)\n",
    "            v = 1 / len(ps) * state.reward(t_board = t_board)\n",
    "            # Si hay recursividad por hacer, se hace\n",
    "            if i > 0:\n",
    "                # Se actualiza de manera recursiva\n",
    "                v = v + self.alpha(self.action(state = state, board = t_board, i = i - 1)[1] + v)\n",
    "            # Se agrega a la lista la tupla (posibiliad, valor)\n",
    "            vs.append((p,v))\n",
    "        # Se regresa el valor mayor\n",
    "        return max(vs, key = lambda x: x[1])\n",
    "    \n",
    "    def reset(self):\n",
    "        self.action = 0\n",
    "        self.state = 0\n",
    "        self.reward = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env: # Juego del Gato\n",
    "    def __init__(self, board = [''] * 9, turn = 0):\n",
    "        self.board = board\n",
    "        self.turn = turn\n",
    "\n",
    "    def reward(self, t_board):\n",
    "        # t_board es el tablero con base en las posibles opciones\n",
    "        # r es la recompensa\n",
    "        r = 0\n",
    "        # player es el jugador 0 o 1 con base en el turno. Es un simple módulo\n",
    "        player = str(self.turn % 2)\n",
    "\n",
    "        # Una victoria se puede dar cuando las casillas verticales, horizontales y diagonales tienen el mismo símbolo, distinto de ''\n",
    "        # Cada turno se revisa si se gana. En ese caso, la recompensa es 1 si el turno coincide con el símbolo ganador. Si se pierde, es -1, en otro caso, 0\n",
    "        \n",
    "        # Victorias horizontales\n",
    "        if self.board[0] != '' and self.board[0] == self.board[1] and self.board[0] == self.board[2]:\n",
    "            if self.turn == self.board[0]:\n",
    "                r = 1\n",
    "            else:\n",
    "                r = -1\n",
    "                \n",
    "        elif self.board[3] != '' and self.board[3] == self.board[4] and self.board[3] == self.board[5]:\n",
    "            if self.turn == self.board[3]:\n",
    "                r = 1\n",
    "            else:\n",
    "                r = -1\n",
    "                \n",
    "        elif self.board[6] != '' and self.board[6] == self.board[7] and self.board[6] == self.board[8]:\n",
    "            if self.turn == self.board[6]:\n",
    "                r = 1\n",
    "            else:\n",
    "                r = -1\n",
    "            \n",
    "        # Victorias verticales\n",
    "        elif self.board[0] != '' and self.board[0] == self.board[3] and self.board[0] == self.board[6]:\n",
    "            if self.turn == self.board[0]:\n",
    "                r = 1\n",
    "            else:\n",
    "                r = -1\n",
    "                \n",
    "        elif self.board[1] != '' and self.board[1] == self.board[4] and self.board[1] == self.board[7]:\n",
    "            if self.turn == self.board[1]:\n",
    "                r = 1\n",
    "            else:\n",
    "                r = -1\n",
    "                \n",
    "        elif self.board[2] != '' and self.board[2] == self.board[5] and self.board[2] == self.board[8]:\n",
    "            if self.turn == self.board[2]:\n",
    "                r = 1\n",
    "            else:\n",
    "                r = -1\n",
    "        \n",
    "        # Victorias diagonales\n",
    "        elif self.board[0] != '' and self.board[0] == self.board[4] and self.board[0] == self.board[8]:\n",
    "            if self.turn =\n",
    "            r = 1\n",
    "        elif self.board[2] != '' and self.board[2] == self.board[4] and self.board[2] == self.board[6]:\n",
    "            if self.turn =\n",
    "            r = 1\n",
    "\n",
    "        return r\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = [''] * 9\n",
    "        self.turn = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['', '', '', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "a = Agent()\n",
    "e = Env()\n",
    "print(e.board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = 10\n",
    "ts = 10\n",
    "for r in range(reps):\n",
    "    e = reset()\n",
    "    a = reset()\n",
    "    for t in range(ts):\n",
    "        # Se elige una acción\n",
    "        t = a.action(state = e, board = e.board, i = 1)\n",
    "        e.board[t[0]] = str(e.turn % 2)\n",
    "        # Se incrementa un turno\n",
    "        e.turn += 1"
   ]
  }
 ]
}